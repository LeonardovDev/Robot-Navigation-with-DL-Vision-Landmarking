# Experimental Setup

## Hardware:

The robot used for this autonomous navigation method is a Kobuki TurtleBot 2, a low-cost, open source differential drive robot by
Yujin Robot. It has reliable odometry sensors, long battery life and provides power for an external sensor and actuators. It consists
of a mobile base, Asus Xtion RGBD camera, and an ODROID XU4 octacore microcomputer.

<p align="center">
  <image src = "Images/kobuki.JPG" width="30%"
</p>

## Test bed:

The test bed was designed for clear classification of defined markers against a plain background. Thus the amount of variables in the
image classification algorithm is minimized with the plain background and the features can be more easily classified. The various markers
are positioned at different locations within the test bed. A picture of test bed is provided in figure below.

<p align="center">
  <image src = "Images/testbed.JPG" width="50%"
</p>

Next section is [Project Implementation](https://github.com/AbhiRP/Autonomous-Robot-Navigation-using-Deep-Learning-Vision-Landmark-Framework/blob/master/Project%20Implementation.md) where the project will be explained throughly. 
