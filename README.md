# Autonomous-Robot-Navigation-using-Deep-Learning-Vision-Landmark-Framework

## Abstract:
Robot navigation requires specific techniques for guiding a mobile robot to a desired destination. In general, a desired path is required in an environment described by different terrain and a set of distinct objects, such as obstacles and particular landmarks. In this project, a new approach for autonomous navigation is presented using machine learning techniques such as Convolutional Neural Network to identify
markers from images and Robot Operating System and Object Position Discovery system to navigate towards these markers.

## Hardware:
1. Yujin Robot Kobuki TurtleBot 2 http://kobuki.yujinrobot.com/
2. Asus Xtion PRO RGB-D Camera https://www.asus.com/3D-Sensor/Xtion_PRO/
3. ODROID-XU4 Octa Core ARM Microcomputer http://www.hardkernel.com/main/main.php

## Software:
1. Ubuntu 14.04 Trusty Tahr http://releases.ubuntu.com/14.04/
2. Robot Operating System (ROS) Indigo http://wiki.ros.org/indigo/Installation
3. TensorFlow https://www.tensorflow.org/install/
4. ImageNet Dataset http://www.image-net.org/

## ROS Package:
depthimage_to_laserscan http://wiki.ros.org/depthimage_to_laserscan

## Documentation:
This project is documented as below:
1. [Project Overview](https://github.com/AbhiRP/Autonomous-Robot-Navigation-using-Deep-Learning-Vision-Landmark-Framework/blob/master/Project%20Overview.md)
2. [Algorithm](https://github.com/AbhiRP/Autonomous-Robot-Navigation-using-Deep-Learning-Vision-Landmark-Framework/blob/master/Algorithm.md)
3. [Experimental Setup]
4. [Project Implementation]
5. [Experimental Results]
